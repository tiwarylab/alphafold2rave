{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bodhivani/RAVEfold/blob/main/heavydemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ613ayE_rlr"
      },
      "source": [
        "# RaveFold colab demo (heavy)\n",
        "\n",
        "This colab is intended to demonstrate in detail the code used in [Vani, Aranganathan et al.](https://doi.org/10.1101/2022.05.25.493365), **\"AlphaFold2-RAVE: From sequence to Boltzmann ensemble\"**. We use the cold-shock protein as our tutorial system.\n",
        "\n",
        "This can be used as a step-by-step runthrough of the entire protocol, and to make this feasible, we have chosen hyperparameters that allow for fast simulations. For robustness, these should be increased as noted.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0w5GZQcHirt"
      },
      "source": [
        "# ColabFold (altered for stochasticity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "edc63342e31f4d5d98e67dbcec4196a5"
          ]
        },
        "id": "5sYM9t4T6J5G",
        "outputId": "4c9e749c-4199-4a46-eb22-780fd4ecbf8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on GPU\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edc63342e31f4d5d98e67dbcec4196a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/55 [elapsed: 00:00 remaining: ?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Install ColabFold\n",
        "# setup device\n",
        "from IPython.display import clear_output\n",
        "!mkdir struct_gen\n",
        "%cd /content/struct_gen/.\n",
        "clear_output()\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import jax\n",
        "\n",
        "try:\n",
        "  # check if TPU is available\n",
        "  import jax.tools.colab_tpu\n",
        "  jax.tools.colab_tpu.setup_tpu()\n",
        "  print('Running on TPU')\n",
        "  DEVICE = \"tpu\"\n",
        "except:\n",
        "  if jax.local_devices()[0].platform == 'cpu':\n",
        "    print(\"WARNING: no GPU detected, will be using CPU\")\n",
        "    DEVICE = \"cpu\"\n",
        "  else:\n",
        "    print('Running on GPU')\n",
        "    DEVICE = \"gpu\"\n",
        "    # disable GPU on tensorflow\n",
        "    tf.config.set_visible_devices([], 'GPU')\n",
        "\n",
        "from IPython.utils import io\n",
        "import subprocess\n",
        "import tqdm.notebook\n",
        "\n",
        "\n",
        "install_jackhmmer = True      #not required\n",
        "\n",
        "#AF2 repo from deepmind\n",
        "GIT_REPO = 'https://github.com/deepmind/alphafold'\n",
        "#AF2 params\n",
        "SOURCE_URL = 'https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar'\n",
        "\n",
        "PARAMS_DIR = './alphafold/data/params'\n",
        "PARAMS_PATH = os.path.join(PARAMS_DIR, os.path.basename(SOURCE_URL))\n",
        "\n",
        "TMP_DIR = \"tmp\"\n",
        "os.makedirs(TMP_DIR, exist_ok=True)\n",
        "\n",
        "#tqdm specification\n",
        "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
        "# if not already installed\n",
        "total = 55\n",
        "with tqdm.notebook.tqdm(total=total, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "  if not os.path.isdir(\"alphafold\"):\n",
        "    # download alphafold code and clone colabfold repo\n",
        "    os.system(f\"git clone {GIT_REPO} alphafold; cd alphafold; git checkout 1d43aaff941c84dc56311076b58795797e49107b\")\n",
        "    os.system(f\"git clone https://github.com/sokrypton/ColabFold.git\")\n",
        "\n",
        "    # apply patches\n",
        "    os.system(f\"patch -u alphafold/alphafold/model/model.py -i ColabFold/beta/model.patch\")\n",
        "    os.system(f\"patch -u alphafold/alphafold/model/mapping.py -i ColabFold/beta/mapping.patch\")\n",
        "    os.system(f\"patch -u alphafold/alphafold/model/modules.py -i ColabFold/beta/modules.patch\")\n",
        "    os.system(f\"patch -u alphafold/alphafold/model/folding.py -i ColabFold/beta/folding.patch\")\n",
        "    os.system(f\"patch -u alphafold/alphafold/model/config.py -i ColabFold/beta/config.patch\")\n",
        "    # apply multi-chain patch from Lim Heo @huhlim\n",
        "    os.system(f\"patch -u alphafold/alphafold/common/protein.py -i ColabFold/beta/protein.patch\")\n",
        "    pbar.update(4)\n",
        "\n",
        "    #install biopython\n",
        "    os.system(f\"pip install biopython dm-haiku==0.0.5 ml-collections py3Dmol\")\n",
        "    pbar.update(6)\n",
        "\n",
        "    # download model params (speedup from kaczmarj)\n",
        "    os.system(f\"mkdir --parents {PARAMS_DIR}\")\n",
        "    os.system(f\"curl -fsSL {SOURCE_URL} | tar x -C {PARAMS_DIR}\")\n",
        "    pbar.update(14+27)\n",
        "\n",
        "    # install hhsuite\n",
        "    os.system(f\"curl -fsSL https://github.com/soedinglab/hh-suite/releases/download/v3.3.0/hhsuite-3.3.0-SSE2-Linux.tar.gz | tar xz -C {TMP_DIR}/\")\n",
        "\n",
        "    # install jackhmmer   #not required and will remove it\n",
        "    if install_jackhmmer:\n",
        "      os.system(f\"sudo apt install --quiet --yes hmmer\")\n",
        "      pbar.update(3)\n",
        "\n",
        "      # create a ramdisk to store a database chunk to make Jackhmmer run fast.\n",
        "      os.system(f\"sudo mkdir -m 777 --parents /tmp/ramdisk\")\n",
        "      os.system(f\"sudo mount -t tmpfs -o size=9G ramdisk /tmp/ramdisk\")\n",
        "      pbar.update(1)\n",
        "\n",
        "    else:\n",
        "      pbar.update(4)\n",
        "\n",
        "  else:\n",
        "    pbar.update(55)\n",
        "\n",
        "###############################################################################################\n",
        "####    Python imports \n",
        "###############################################################################################\n",
        "if 'alphafold' not in sys.path:\n",
        "  sys.path.append('alphafold')\n",
        "if 'ColabFold/beta' not in sys.path:\n",
        "  sys.path.append('ColabFold/beta')\n",
        "\n",
        "if f\"{TMP_DIR}/bin\" not in os.environ['PATH']:\n",
        "  os.environ['PATH'] += f\":{TMP_DIR}/bin:{TMP_DIR}/scripts\"\n",
        "\n",
        "import colabfold as cf\n",
        "import colabfold_alphafold as cf_af\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "!cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "43f82bd7d98949939235e826a7579d53",
            "78acc86afca54f46b7f1bf080d5fa23e",
            "8fc233c42ce941a9a0f89b6a3d620795",
            "e262e80f569344a3bb7d7c3ef76fcc82",
            "ed9e9b16fd7f4067994912c41485f16c",
            "197266db3e7d435ebfd65a2e067c06be",
            "db6f48ebfa834a499854b1ecde50f6ef",
            "6c27402693d74db9a800f135bc95309f",
            "e56032e24729445aa47ffb70fede3d03",
            "fca48d39301c40098d86c3828db2bb63",
            "757133d0b3be47b7ac288f99af17001d"
          ]
        },
        "id": "bbiYErPlmEvp",
        "outputId": "ffd1486a-b5ff-410c-f133-ba9a92b93313"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43f82bd7d98949939235e826a7579d53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/640 [elapsed: 00:00 remaining: ?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Run Colabfold with reduced MSA\n",
        "#Code was taken from COLABFOLD git and modified for convenience \n",
        "import re\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/struct_gen/.\n",
        "#####################################################################################################################\n",
        "###    Input sequence\n",
        "#####################################################################################################################\n",
        "\n",
        "#@markdown Change this to the amino acid sequence of your system\n",
        "sequence = 'MQRGKVKWFNNEKGYGFIEVEGGSDVFVHFTAIQGEGFKTLEEGQEVSFEIVQGNRGPQAANVVKE' #@param {type:\"string\"}\n",
        "jobname = \"CSP\" #@param {type:\"string\"}\n",
        "homooligomer =  \"1\" #param {type:\"string\"}\n",
        "\n",
        "\n",
        "#####################################################################################################################\n",
        "###    MSA parameters\n",
        "#####################################################################################################################\n",
        "\n",
        "add_custom_msa = False \n",
        "msa_format = \"fas\" \n",
        "pair_mode = \"unpaired\" \n",
        "pair_cov = 50 \n",
        "pair_qid = 20 \n",
        "\n",
        "I = cf_af.prep_inputs(sequence, jobname, homooligomer, clean=IN_COLAB)\n",
        "msa_method = \"mmseqs2\" \n",
        "#I['output_dir']='_'.join(I['output_dir'].split('_')[:-1])\n",
        "I = cf_af.prep_msa(I, msa_method, add_custom_msa, msa_format,\n",
        "                   pair_mode, pair_cov, pair_qid, TMP_DIR=TMP_DIR)\n",
        "mod_I = I\n",
        "clear_output() # ----> Clear the output from previous functions\n",
        "#No relaxation \n",
        "num_relax = \"None\"\n",
        "\n",
        "\n",
        "#####################################################################################################################\n",
        "###    Parameters for running Alphafold\n",
        "#####################################################################################################################\n",
        "rank_by = \"pLDDT\" \n",
        "use_turbo = True \n",
        "#@markdown This parameter can be \"tuned\". Too low, and it doesn't have enough information for sensible predictions. Too high, and it will not generate structural diversity\n",
        "max_msa = \"08:16\" #@param [\"512:1024\", \"256:512\", \"128:256\", \"64:128\", \"32:64\",\"16:32\",\"08:16\",\"04:08\",\"02:04\",\"01:02\",\"02:02\"]\n",
        "#@markdown - `max_msa` defines: `max_msa_clusters:max_extra_msa` number of sequences to use. \n",
        "max_msa_clusters, max_extra_msa = [int(x) for x in max_msa.split(\":\")]\n",
        "\n",
        "show_images = False \n",
        "\n",
        "num_models = 5 \n",
        "use_ptm = True \n",
        "num_ensemble = 1 \n",
        "max_recycles = 1 \n",
        "is_training = True \n",
        "num_samples = 128 #@param [1,2,4,8,16,32,64,128] {type:\"raw\"}\n",
        "#@markdown - `num_samples` defines the number of random seed. (For each seed 5 different models are predicted)  \n",
        "subsample_msa = True \n",
        "\n",
        "if not use_ptm and rank_by == \"pTMscore\":\n",
        "  print(\"WARNING: models will be ranked by pLDDT, 'use_ptm' is needed to compute pTMscore\")\n",
        "  rank_by = \"pLDDT\"\n",
        "\n",
        "# prep input features\n",
        "feature_dict = cf_af.prep_feats(mod_I, clean=IN_COLAB)\n",
        "Ls_plot = feature_dict[\"Ls\"]\n",
        "\n",
        "# prep model options\n",
        "opt = {\"N\":len(feature_dict[\"msa\"]),\n",
        "       \"L\":len(feature_dict[\"residue_index\"]),\n",
        "       \"use_ptm\":use_ptm,\n",
        "       \"use_turbo\":use_turbo,\n",
        "       \"max_recycles\":max_recycles,\n",
        "       \"tol\":0.0,\n",
        "       \"num_ensemble\":num_ensemble,\n",
        "       \"max_msa_clusters\":max_msa_clusters,\n",
        "       \"max_extra_msa\":max_extra_msa,\n",
        "       \"is_training\":is_training}\n",
        "\n",
        "if use_turbo:\n",
        "  if \"runner\" in dir():\n",
        "    # only recompile if options changed\n",
        "    runner = cf_af.prep_model_runner(opt, old_runner=runner)\n",
        "  else:\n",
        "    runner = cf_af.prep_model_runner(opt)\n",
        "else:\n",
        "  runner = None\n",
        "\n",
        "#####################################################################################################################\n",
        "###    Run Alphafold with low MSA \n",
        "#####################################################################################################################\n",
        "t1 = time.perf_counter()\n",
        "outs, model_rank = cf_af.run_alphafold(feature_dict, opt, runner, num_models, num_samples, subsample_msa,\n",
        "                                       rank_by=rank_by, show_images=show_images)\n",
        "\n",
        "\n",
        "\n",
        "#####################################################################################################################\n",
        "###    Output folder\n",
        "#####################################################################################################################\n",
        "\n",
        "structures_path='/content/Structures'   #Output_folder\n",
        "os.makedirs(structures_path)\n",
        "file_path=os.path.join(structures_path,'file_details.txt')\n",
        "with open(file_path, \"w\") as file_details:\n",
        "  for n,key in enumerate(model_rank):\n",
        "    copy_line=f'cp {I[\"output_dir\"]}/rank_{n+1}_{key}_unrelaxed.pdb {structures_path}/pred_{n+1}.pdb'\n",
        "    os.system(copy_line)\n",
        "    if num_relax !=\"None\":\n",
        "      if n<num_relax: \n",
        "        copy_line2=f'cp {I[\"output_dir\"]}/rank_{n+1}_{key}_relaxed.pdb {structures_path}/pred_{n+1}.pdb'\n",
        "        os.system(copy_line2)\n",
        "    line = f\"pred_{n+1}.pdb pLDDT:{outs[key]['pLDDT']:.2f}\" + f\" pTMscore:{outs[key]['pTMscore']:.4f}\" if use_ptm else \"\"\n",
        "    file_details.write(line+\"\\n\")\n",
        "\n",
        "#os.system(f'rm -r {I[output_dir]}')   #--> run this line to delete the second copy of structures\n",
        "%cd /content/\n",
        "os.system(f'zip -FSr Structures.zip {structures_path}')\n",
        "t2 = time.perf_counter()\n",
        "clear_output()\n",
        "print('\\nTime taken to generate:',(t2-t1)/60,' mins')\n",
        "\n",
        "print(f'The structures can be found in {structures_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2lt11PSHeGi"
      },
      "source": [
        "# Installations for molecular dynamics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mek6Y0S3icAK",
        "outputId": "d6eee6b4-ce0f-434e-a7fc-ff38abbd58ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting condacolab\n",
            "  Downloading condacolab-0.1.4-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: condacolab\n",
            "Successfully installed condacolab-0.1.4\n",
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:27\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "#@title Install condacolab\n",
        "#@markdown After running this cell wait for the kernel to restart (~1min)\n",
        "\n",
        "#@markdown Then, start running the rest of the blocks\n",
        "try:\n",
        "    import google.colab\n",
        "    !pip install condacolab\n",
        "    import condacolab\n",
        "    condacolab.install()\n",
        "except ModuleNotFoundError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G441cmKTjDYy",
        "outputId": "602477e2-ca5e-4340-b447-c8d67125ea1c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies successfully installed and imported!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken to run:11.68 mins\n"
          ]
        }
      ],
      "source": [
        "#@title Install OpenMM with Plumed\n",
        "#@markdown Run this to install and import libraries \n",
        "import time\n",
        "t1 = time.perf_counter()\n",
        "try:\n",
        "    import condacolab\n",
        "    from google.colab import files\n",
        "    from IPython.display import clear_output\n",
        "    condacolab.check()\n",
        "    #!conda install -qy conda==4.13.0\n",
        "    !conda install -q -y -c conda-forge openmm cudatoolkit=11.2 openmmforcefields openmm-plumed pdbfixer mdtraj\n",
        "    !conda install -qy pytorch==1.8.0 -c pytorch -c nvidia\n",
        "    on_colab = True\n",
        "    clear_output()             # clear the excessive installation outputs (disable incase of error check)\n",
        "    print(\"Dependencies successfully installed and imported!\")\n",
        "except ModuleNotFoundError:\n",
        "    on_colab = False\n",
        "\n",
        "\n",
        "# required for simulation with Plumed on gpu\n",
        "from sys import stdout\n",
        "from openmmplumed import PlumedForce\n",
        "from openmm.app import *\n",
        "from openmm import *\n",
        "from openmm.unit import *\n",
        "import pdbfixer\n",
        "\n",
        "# required for analysis\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "t2 = time.perf_counter()\n",
        "print(f'time taken to run:{(t2-t1)/60:.2f} mins')\n",
        "\n",
        "#create the directory for colabfold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTuAXIwvH9Al"
      },
      "source": [
        "# Setup initial files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6toIzQOnaRgy",
        "outputId": "5efbbb02-29a0-464a-82a7-ef664885c597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'RAVEfold': No such file or directory\n",
            "Cloning into 'RAVEfold'...\n",
            "remote: Enumerating objects: 187, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 187 (delta 32), reused 0 (delta 0), pack-reused 127\u001b[K\n",
            "Receiving objects: 100% (187/187), 6.56 MiB | 19.82 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "Cloning into 'State-Predictive-Information-Bottleneck'...\n",
            "remote: Enumerating objects: 140, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 140 (delta 1), reused 0 (delta 0), pack-reused 122\u001b[K\n",
            "Receiving objects: 100% (140/140), 5.87 MiB | 19.65 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ]
        }
      ],
      "source": [
        "#@title Import other requirements\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!rm -r RAVEfold \n",
        "!git clone https://github.com/bodhivani/RAVEfold\n",
        "\n",
        "!cp RAVEfold/ravefuncs.py .\n",
        "import ravefuncs as rave\n",
        "import importlib\n",
        "importlib.reload(rave)\n",
        "\n",
        "!git clone https://github.com/tiwarylab/State-Predictive-Information-Bottleneck\n",
        "%rm -r State-Predictive-Information-Bottleneck/examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HtNhENtAD-mk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Analysis on AF2 structures\n",
        "if os.path.isdir(\"Structures\")==False:\n",
        "  os.system(\"unzip RAVEfold/CSP_data/structures.zip -d .\")\n",
        "  num_samples=128\n",
        "\n",
        "tot=num_samples*5\n",
        "os.chdir(\"Structures\")\n",
        "os.system('cp ../RAVEfold/CSP_data/plumed_AF2.dat .')\n",
        "inputline=' '.join([f'pred_{i+1}.pdb' for i in range(tot)])\n",
        "os.system(f'mdconvert {inputline} -o AF2samples.xtc')\n",
        "os.system('plumed driver --plumed plumed_AF2.dat --ixtc AF2samples.xtc')\n",
        "os.chdir(\"..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fj1dIUdcn0W",
        "outputId": "5d0228d8-cd16-49b3-ac20-39a1fd0a5efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 centers!\n"
          ]
        }
      ],
      "source": [
        "#@title Cluster to initialize RAVEfold\n",
        "CVs=np.loadtxt(\"Structures/COLVARS_AF2.dat\")[:,1:]\n",
        "centers,listindices=rave.RegSpaceClustering(CVs,6.5,max_centers=10, batch_size=50) #change to 5 or 5.5 for robustness\n",
        "t_af2=rave.getTrp8(CVs)\n",
        "t_cluster=rave.getTrp8(centers.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPZrcoohILZ6"
      },
      "source": [
        "# RAVEfold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N79bx1VRhR0l",
        "outputId": "eb1834eb-16f6-4236-b77e-c9f3523f6b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are at /content/unbiased/1\n",
            "We are at /content/unbiased/366\n",
            "We are at /content/unbiased/627\n",
            "time taken to run:3.01 mins\n"
          ]
        }
      ],
      "source": [
        "#@title Unbiased simulations\n",
        "t1 = time.perf_counter()\n",
        "if os.path.isdir(\"Structures\")==False:\n",
        "  os.system(\"unzip RAVEfold/CSP_data/structures.zip -d .\")\n",
        "  num_samples=128\n",
        "  listindices=[1, 224, 627, 533]\n",
        "  \n",
        "#@markdown Check the below box to run on GPU\n",
        "on_gpu=True #@param {type:\"boolean\"}\n",
        "#@markdown MD parameters\n",
        "\n",
        "#@markdown Integration Timestep (ps)\n",
        "dt =0.004 #@param{type:\"number\"}\n",
        "#@markdown Temperature (K)\n",
        "temp=300 #@param{type:\"number\"}\n",
        "freq=1 #param{type:\"number\"}\n",
        "#@markdown Number of steps \n",
        "nstep=40000 #@param{type:\"number\"}\n",
        "#markdown Plumed file\n",
        "plumedfile=\"plumed_unb.dat\" #param{type:\"string\"}\n",
        "\n",
        "os.mkdir(\"unbiased\")\n",
        "os.chdir(\"./unbiased\")\n",
        "cpath=os.getcwd()\n",
        "os.system('cp /content/RAVEfold/CSP_data/plumed_unb.dat .')\n",
        "plumedfile=os.path.join(cpath,plumedfile)\n",
        "for index in listindices:\n",
        "  os.mkdir(f'{index}')\n",
        "  os.chdir(f'./{index}')\n",
        "  os.system(f\"cp /content/Structures/pred_{index}.pdb .\")\n",
        "  rave.run_unbiased(on_gpu,plumedfile,dt,temp,freq,nstep,index)\n",
        "  os.chdir(\"..\")\n",
        "\n",
        "os.chdir(\"..\")\n",
        "t2 = time.perf_counter()\n",
        "print(f'time taken to run:{(t2-t1)/60:.2f} mins')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rm -r SPIB_unbiased/"
      ],
      "metadata": {
        "id": "5wdgEazsl7aP"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXjNDnsT-H0F",
        "outputId": "1072204c-f2f9-4424-d283-2775174a6f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "#@title SPIB on unbiased simulations\n",
        "%cd /content/\n",
        "if os.path.isdir(\"SPIB_unbiased\"):\n",
        "  os.system(\"rm -r SPIB_unbiased\")\n",
        "cvs=[]\n",
        "os.mkdir(\"SPIB_unbiased\")\n",
        "os.chdir(\"SPIB_unbiased\")\n",
        "num_state=len(listindices)*2\n",
        "for i,index in enumerate(listindices):\n",
        "    cvs.append(np.loadtxt(\"../unbiased/%i/COLVAR_unb.dat\"%index)[:,1:])\n",
        "    np.save(\"colvar_%i_unb.npy\"%i,cvs[i])\n",
        "    lentraj=len(cvs[i])\n",
        "    zeroone=np.hstack([np.zeros(int(lentraj/2),dtype=np.int8),np.ones(lentraj-int(lentraj/2),dtype=np.int8)])\n",
        "    initlabels=np.eye(num_state)[zeroone+int(i*2)]\n",
        "    np.save(\"labels_%i_unb.npy\"%i,initlabels)\n",
        "\n",
        "dt=2\n",
        "\n",
        "\n",
        "f_nodt=open('../RAVEfold/sample_config.ini')\n",
        "f=open('config.ini','w')\n",
        "lines=f_nodt.readlines()\n",
        "lines.insert(2,f'dt =[{dt}]\\n')\n",
        "f.writelines(lines)\n",
        "f_nodt.close()\n",
        "\n",
        "unbpath=\"unbiased\"\n",
        "\n",
        "f.write(\"\\n traj_data = [%s]\\n\"%\",\".join([\"%s/colvar_%i_unb.npy\"%(unbpath,i) for i in range(len(cvs))]))\n",
        "\n",
        "f.write(\"\\n initial_labels = [%s]\\n\"%\",\".join([\"%s/labels_%i_unb.npy\"%(unbpath,i) for i in range(len(cvs))]))\n",
        "\n",
        "f.write(\"\\n traj_weights \\n\")\n",
        "\n",
        "f.close()\n",
        "\n",
        "os.chdir(\"..\")\n",
        "%mv SPIB_unbiased State-Predictive-Information-Bottleneck/unbiased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYSHlVCX0_Tk",
        "outputId": "6a645346-de6b-44d2-b57e-eea063760203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/State-Predictive-Information-Bottleneck\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.811608\n",
            "Update lr to 0.010000\n",
            "Epoch: 1\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 2\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 3\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Update 1\n",
            "\n",
            "Epoch: 0\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 1\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 2\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Update 2\n",
            "\n",
            "Epoch: 0\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 1\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 2\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Update 3\n",
            "\n",
            "Epoch: 0\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 1\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 2\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Update 4\n",
            "\n",
            "Epoch: 0\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 1\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 2\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Update 5\n",
            "\n",
            "Epoch: 0\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 1\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 2\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Update 6\n",
            "\n",
            "Epoch: 0\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 1\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 2\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Update 7\n",
            "\n",
            "Epoch: 0\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 1\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 2\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Update 8\n",
            "\n",
            "Epoch: 0\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 1\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Epoch: 2\n",
            "\n",
            "tensor([0.1313, 0.0000, 0.0000, 0.0000, 0.8687, 0.0000])\n",
            "State population change=0.000000\n",
            "Update lr to 0.010000\n",
            "Total training time: 0.122140\n",
            "Final: 0\n",
            "Loss (train) 1.738789\tKL loss (train): 6.211609\n",
            "Reconstruction loss (train) 1.676673\n",
            "Loss (test) 1.717074\tKL loss (train): 4.121018\n",
            "Reconstruction loss (test) 1.675864\n",
            "dt: 2\t Beta: 0.010000\t Learning_rate: 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/State-Predictive-Information-Bottleneck/\n",
        "%run test_model_advanced.py -config unbiased/config.ini"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HniOfKcumoZk",
        "outputId": "6d4bbc5f-2a18-4659-f6db-1ec7fb42a2d2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/State-Predictive-Information-Bottleneck'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix='SPIB/Unweighted_d=2_t=%i_b=0.0100_learn=0.010000_'%dt\n",
        "weights=np.load(prefix+\"z_mean_encoder_weight0.npy\")\n",
        "lspace=[np.load(prefix+\"traj%i_mean_representation0.npy\"%i) for i in range(len(cvs))]\n",
        "lstacked=np.vstack([np.hstack([lspace[j][:,i] for j in range(len(cvs))]) for i in range(2)])\n",
        "wid1=np.std(lstacked[0])/5\n",
        "wid2=np.std(lstacked[1])/5"
      ],
      "metadata": {
        "id": "iX5xfkA6miEG"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wid1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK0Y-YSXm14q",
        "outputId": "0d776135-d610-4b17-85f6-dc5e69a1b07b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.044227153062820435"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyi3j_Hp1R_3"
      },
      "outputs": [],
      "source": [
        "#@title Biased simulations\n",
        "\n",
        "#@markdown Here we are using already solvated and equilibrated system(from GMX)\n",
        "\n",
        "# Inputs definition \n",
        "\n",
        "#@markdown metadynamics parameters\n",
        "height = 1.5 #@param{type:\"number\"}\n",
        "biasfactor=10 #@param{type:\"number\"}\n",
        "#@markdown standard deviation of deposited gaussians\n",
        "width1= 1 #@param{type:\"number\"}\n",
        "width2= 1 #@param{type:\"number\"}\n",
        "#@markdown metadynamics gridparameters\n",
        "gridmin1=1 #@param{type:\"number\"}\n",
        "gridmin2=1 #@param{type:\"number\"}\n",
        "gridmax1=1 #@param{type:\"number\"}\n",
        "gridmax2=1 #@param{type:\"number\"}\n",
        "#@markdown Length of metadynamics simulation\n",
        "\n",
        "\n",
        "!cp RAVEfold/CSPdata/plumed_full.dat . plumed_biased.dat\n",
        "colvar=\"sc1_r1,cc1_r1,sc1_r2,cc1_r2,sc1_r3,cc1_r3,sc1_r5,cc1_r5,sc1_r6,cc1_r6,sc1_r7,cc1_r7,sc1_r8,cc1_r8,sc1_r9,cc1_r9,sc1_r10,cc1_r10,sc1_r11,cc1_r11,sc1_r12,cc1_r12,sc1_r13,cc1_r13,sc1_r15,cc1_r15,sc1_r17,cc1_r17,sc1_r18,cc1_r18,sc1_r19,cc1_r19,sc1_r20,cc1_r20,sc1_r21,cc1_r21,sc1_r24,cc1_r24,sc1_r25,cc1_r25,sc1_r26,cc1_r26,sc1_r27,cc1_r27,sc1_r28,cc1_r28,sc1_r29,cc1_r29,sc1_r30,cc1_r30,sc1_r31,cc1_r31,sc1_r33,cc1_r33,sc1_r34,cc1_r34,sc1_r36,cc1_r36,sc1_r38,cc1_r38,sc1_r39,cc1_r39,sc1_r40,cc1_r40,sc1_r41,cc1_r41,sc1_r42,cc1_r42,sc1_r43,cc1_r43,sc1_r45,cc1_r45,sc1_r46,cc1_r46,sc1_r47,cc1_r47,sc1_r48,cc1_r48,sc1_r49,cc1_r49,sc1_r50,cc1_r50,sc1_r51,cc1_r51,sc1_r52,cc1_r52,sc1_r53,cc1_r53,sc1_r55,cc1_r55,sc1_r56,cc1_r56,sc1_r58,cc1_r58,sc1_r59,cc1_r59,sc1_r62,cc1_r62,sc1_r63,cc1_r63,sc1_r64,cc1_r64,sc1_r65,cc1_r65,sc1_r66,cc1_r66,sc2_r1,cc2_r1,sc2_r2,cc2_r2,sc2_r3,cc2_r3,sc2_r5,cc2_r5,sc2_r7,cc2_r7,sc2_r8,cc2_r8,sc2_r9,cc2_r9,sc2_r10,cc2_r10,sc2_r11,cc2_r11,sc2_r12,cc2_r12,sc2_r13,cc2_r13,sc2_r15,cc2_r15,sc2_r17,cc2_r17,sc2_r18,cc2_r18,sc2_r19,cc2_r19,sc2_r21,cc2_r21,sc2_r25,cc2_r25,sc2_r27,cc2_r27,sc2_r29,cc2_r29,sc2_r30,cc2_r30,sc2_r33,cc2_r33,sc2_r34,cc2_r34,sc2_r36,cc2_r36,sc2_r38,cc2_r38,sc2_r39,cc2_r39,sc2_r41,cc2_r41,sc2_r42,cc2_r42,sc2_r43,cc2_r43,sc2_r45,cc2_r45,sc2_r46,cc2_r46,sc2_r49,cc2_r49,sc2_r50,cc2_r50,sc2_r51,cc2_r51,sc2_r53,cc2_r53,sc2_r55,cc2_r55,sc2_r56,cc2_r56,sc2_r58,cc2_r58,sc2_r59,cc2_r59,sc2_r62,cc2_r62,sc2_r65,cc2_r65,sc2_r66,cc2_r66,sc3_r1,cc3_r1,sc3_r2,cc3_r2,sc3_r3,cc3_r3,sc3_r5,cc3_r5,sc3_r7,cc3_r7,sc3_r12,cc3_r12,sc3_r13,cc3_r13,sc3_r19,cc3_r19,sc3_r21,cc3_r21,sc3_r34,cc3_r34,sc3_r36,cc3_r36,sc3_r39,cc3_r39,sc3_r42,cc3_r42,sc3_r43,cc3_r43,sc3_r45,cc3_r45,sc3_r46,cc3_r46,sc3_r50,cc3_r50,sc3_r53,cc3_r53,sc3_r56,cc3_r56,sc3_r59,cc3_r59,sc3_r65,cc3_r65,sc3_r66,cc3_r66,sc4_r3,cc4_r3,sc4_r5,cc4_r5,sc4_r7,cc4_r7,sc4_r13,cc4_r13,sc4_r39,cc4_r39,sc4_r56,cc4_r56,sc4_r65,cc4_r65,sc5_r3,cc5_r3,sc5_r56,cc5_r56\"\n",
        "plumedfile=\"plumed_biased.dat\"\n",
        "make_biased_plumed(plumedfile,weights,colvar,height,biasfactor,width1,width2,gridmin1,gridmin2,gridmax1,gridmax2)\n",
        "\n",
        "pdbfile=\"Structures/pred_1.pdb\"\n",
        "run_biased_plumed(pdbfile,time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "9JGJULWvrt5J",
        "outputId": "8662f961-0f37-468c-c3a8-714e7aaea0df"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2dcd80c449c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplumedfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"COLVARS.dat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mCVs_metad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplumedfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplumedfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt_af2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTrp8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCVs_metad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: COLVARS.dat not found."
          ]
        }
      ],
      "source": [
        "plumedfile=np.loadtxt(\"COLVARS.dat\")[:,1:]\n",
        "CVs_metad=plumedfile[:,:250]\n",
        "w=np.exp(plumedfile[-1])\n",
        "\n",
        "t_af2=rave.getTrp8(CVs_metad)\n",
        "\n",
        "H,xlims,ylims=np.histogram2d(CVs_metad,data[:,cv1],bins=100,weights=w)\n",
        "xlims=(xlims[1:]+xlims[:-1])/2\n",
        "ylims=(ylims[1:]+ylims[:-1])/2\n",
        "plt.contourf(xlims,ylims,-np.log(H).T+np.max(np.log(H)),\"-w\",levels=10,cmap=\"plasma\",LineWidth=1)\n",
        "cbar=plt.colorbar()\n",
        "cbar.set_label(\"Free energy $(K_BT)$\")\n",
        "plt.contour(xlims,ylims,-np.log(H).T+np.max(np.log(H)),colors=\"white\",levels=10,linewidths=0.5)\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.xlabel(\"$\\chi_1$ (radians)\")\n",
        "plt.ylabel(\"$\\chi_2$ (radians)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rfwsfBC8WbJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "r0w5GZQcHirt",
        "w2lt11PSHeGi"
      ],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "197266db3e7d435ebfd65a2e067c06be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43f82bd7d98949939235e826a7579d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78acc86afca54f46b7f1bf080d5fa23e",
              "IPY_MODEL_8fc233c42ce941a9a0f89b6a3d620795",
              "IPY_MODEL_e262e80f569344a3bb7d7c3ef76fcc82"
            ],
            "layout": "IPY_MODEL_ed9e9b16fd7f4067994912c41485f16c"
          }
        },
        "6c27402693d74db9a800f135bc95309f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757133d0b3be47b7ac288f99af17001d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78acc86afca54f46b7f1bf080d5fa23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_197266db3e7d435ebfd65a2e067c06be",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_db6f48ebfa834a499854b1ecde50f6ef",
            "value": "Running model_1_ptm_seed_0:   0%"
          }
        },
        "8fc233c42ce941a9a0f89b6a3d620795": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c27402693d74db9a800f135bc95309f",
            "max": 640,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e56032e24729445aa47ffb70fede3d03",
            "value": 0
          }
        },
        "db6f48ebfa834a499854b1ecde50f6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e262e80f569344a3bb7d7c3ef76fcc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fca48d39301c40098d86c3828db2bb63",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_757133d0b3be47b7ac288f99af17001d",
            "value": " 0/640 [elapsed: 00:05 remaining: ?]"
          }
        },
        "e56032e24729445aa47ffb70fede3d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed9e9b16fd7f4067994912c41485f16c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fca48d39301c40098d86c3828db2bb63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}